{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tintubiel/MSU_ML_MFK/blob/main/gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Градиентный спуск\n",
        "\n",
        "В этом задании нам предстоит реализовать классический алгоритм градиентного спуска для обучения модели логистической регрессии.\n",
        "\n",
        "Алгоритм выполнения этого задания следующий:\n",
        "\n",
        "* На основе посчитанных в первом задании частных производных, напишем функцию подсчета градиента бинарной кросс-энтропии по параметрам модели\n",
        "\n",
        "* Напишем функцию обновления весов по посчитанным градиентам \n",
        "\n",
        "* Напишем функцию тренировки модели\n",
        "\n",
        "Замечание:\n",
        "Тренировка модели проводится в несколько циклов, в рамках каждого из которых мы обновим веса модели, основываясь на предсказании для **каждого** объекта из датасета. Такие циклы называются *эпохами*. То есть одна эпоха - это набор обновлений весов, реализованный согласно посчитанным для каждого объекта из датасета ошибкам модели.\n",
        "\n",
        "Вам необходимо реализовать обучение модели в несколько эпох. Их количество задается параметром функции. В рамках каждой эпохи необходимо пройти циклом по всем объектам обучающей выборки и обновить веса модели."
      ],
      "metadata": {
        "id": "zVKa9zcWdm-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаблон кода для заполнения:"
      ],
      "metadata": {
        "id": "zrTqdyBid_G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Функция подсчета градиента\n",
        "def gradient(y_true: int, y_pred: float, x: np.array) -> np.array:\n",
        "  \"\"\"\n",
        "    y_true - истинное значение ответа для объекта x\n",
        "    y_pred - значение степени принадлежности объекта x классу 1, предсказанное нашей моделью\n",
        "    x - вектор признакового описания данного объекта\n",
        "\n",
        "    На выходе ожидается получить вектор частных производных H по параметрам модели, предсказавшей значение y_pred\n",
        "    Обратите внимание, что размерность этого градиента должна получиться на единицу больше размерности x засчет своободного коэффициента a0\n",
        "  \"\"\"\n",
        "  grad=np.array([])\n",
        "  x=np.append(x,1)\n",
        "  for i in range(len(x)):\n",
        "    delta_h=x[i]*((1-y_true)*y_pred-y_true*(1-y_pred))\n",
        "    grad=np.append(grad,delta_h)\n",
        "  return grad\n",
        "\n",
        "\n",
        "# Функция обновления весов\n",
        "def update(alpha: np.array, gradient: np.array, lr: float):\n",
        "  \"\"\"\n",
        "  alpha: текущее приближения вектора параметров модели\n",
        "  gradient: посчитанный градиент по параметрам модели\n",
        "  lr: learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "  \"\"\"\n",
        "  print(alpha)\n",
        "  alpha_new = alpha-lr*gradient\n",
        "  return alpha_new\n",
        "\n",
        "#функция тренировки модели\n",
        "def train(alpha0: np.array, x_train: np.array, y_train: np.array, lr: float, num_epoch: int):\n",
        "  \"\"\"\n",
        "  alpha0 - начальное приближение параметров модели\n",
        "  x_train - матрица объект-признак обучающей выборки\n",
        "  y_train - верные ответы для обучающей выборки\n",
        "  lr - learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "  num_epoch - количество эпох обучения, то есть полных 'проходов' через весь датасет\n",
        "  \"\"\"\n",
        "  alpha = alpha0.copy()\n",
        "  for epo in range(num_epoch):\n",
        "    print(epo)\n",
        "    for i,x in enumerate(x_train):\n",
        "      y_pred = 1/(1 + np.exp(np.dot(alpha,np.append(x,1))))\n",
        "      grad = gradient(y_train[i], y_pred, x)\n",
        "      alpha = update(alpha, grad, lr)\n",
        "  return alpha"
      ],
      "metadata": {
        "id": "CCM4EIh_d8-n"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array([[0,1],[2,4],[-1,2],[-3,-1]])\n",
        "y_train=np.array([[0],[0],[1],[1]])\n",
        "lr=0.01\n",
        "num_epoch=20\n",
        "alpha0=np.array([-0.5,-0.5,0])\n",
        "\n",
        "\n",
        "print(train(alpha0, x_train, y_train, lr, num_epoch))"
      ],
      "metadata": {
        "id": "zG0d6EeIYloa",
        "outputId": "98457b01-dc2a-4397-a628-922e2d24d263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[-0.5 -0.5  0. ]\n",
            "[-0.5        -0.50622459 -0.00622459]\n",
            "[-0.51907921 -0.54438301 -0.0157642 ]\n",
            "[-0.522656   -0.53722943 -0.01218741]\n",
            "1\n",
            "[-0.54936266 -0.54613165 -0.00328519]\n",
            "[-0.54936266 -0.55247165 -0.00962519]\n",
            "[-0.56866364 -0.59107362 -0.01927568]\n",
            "[-0.5721325  -0.58413591 -0.01580683]\n",
            "2\n",
            "[-0.59936062 -0.59321196 -0.00673079]\n",
            "[-0.59936062 -0.59966839 -0.01318722]\n",
            "[-0.61883413 -0.63861541 -0.02292398]\n",
            "[-0.6221938  -0.63189608 -0.01956431]\n",
            "3\n",
            "[-0.64987331 -0.64112258 -0.01033781]\n",
            "[-0.64987331 -0.64769598 -0.0169112 ]\n",
            "[-0.66947939 -0.68690813 -0.02671424]\n",
            "[-0.67272903 -0.68040885 -0.0234646 ]\n",
            "4\n",
            "[-0.70079532 -0.68976428 -0.01410917]\n",
            "[-0.70079532 -0.69645474 -0.02079963]\n",
            "[-0.72050222 -0.73586854 -0.03065308]\n",
            "[-0.72364135 -0.72959028 -0.02751395]\n",
            "5\n",
            "[-0.75203622 -0.73905524 -0.01804899]\n",
            "[-0.75203622 -0.74586248 -0.02485624]\n",
            "[-0.77181915 -0.78542835 -0.03474771]\n",
            "[-0.77484761 -0.77937145 -0.03171925]\n",
            "6\n",
            "[-0.80351954 -0.78892876 -0.02216194]\n",
            "[-0.80351954 -0.79585218 -0.02908536]\n",
            "[-0.82335942 -0.83553194 -0.0390053 ]\n",
            "[-0.82627731 -0.82969615 -0.03608741]\n",
            "7\n",
            "[-0.85518145 -0.83933086 -0.0264527 ]\n",
            "[-0.85518145 -0.84636954 -0.03349137]\n",
            "[-0.87506374 -0.88613411 -0.04343252]\n",
            "[-0.87787145 -0.88051868 -0.0406248 ]\n",
            "8\n",
            "[-0.90696919 -0.89021793 -0.03092555]\n",
            "[-0.90696919 -0.89737068 -0.0380783 ]\n",
            "[-0.9268829  -0.9371981  -0.04803516]\n",
            "[-0.92958108 -0.93180175 -0.04533699]\n",
            "9\n",
            "[-0.95883955 -0.94155458 -0.03558416]\n",
            "[-0.95883955 -0.94881998 -0.04284956]\n",
            "[-0.97877646 -0.9886938  -0.05281802]\n",
            "[-0.98136597 -0.98351479 -0.05022851]\n",
            "10\n",
            "[-1.01075742 -0.99331194 -0.04043136]\n",
            "[-1.01075742 -1.00068835 -0.04780777]\n",
            "[-1.0307114  -1.04059631 -0.05778476]\n",
            "[-1.03319334 -1.03563242 -0.05530282]\n",
            "11\n",
            "[-1.06269451 -1.04546614 -0.0454691 ]\n",
            "[-1.06269451 -1.05295172 -0.05295467]\n",
            "[-1.082661   -1.09288471 -0.06293792]\n",
            "[-1.08503671 -1.0881333  -0.06056222]\n",
            "12\n",
            "[-1.11462818 -1.09799713 -0.05069839]\n",
            "[-1.11462818 -1.10558985 -0.05829112]\n",
            "[-1.13460383 -1.14554116 -0.06827895]\n",
            "[-1.13687484 -1.14099916 -0.06600794]\n",
            "13\n",
            "[-1.1665405  -1.15088771 -0.05611939]\n",
            "[-1.1665405  -1.1585854  -0.06381708]\n",
            "[-1.18652284 -1.19855008 -0.07380825]\n",
            "[-1.18869089 -1.19421399 -0.0716402 ]\n",
            "14\n",
            "[-1.21841743 -1.20412283 -0.06173135]\n",
            "[-1.21841743 -1.21192316 -0.06953168]\n",
            "[-1.23840464 -1.25189757 -0.07952528]\n",
            "[-1.24047167 -1.24776352 -0.07745825]\n",
            "15\n",
            "[-1.27024809 -1.25768899 -0.06753278]\n",
            "[-1.27024809 -1.26558948 -0.07543327]\n",
            "[-1.29023884 -1.30557098 -0.08542864]\n",
            "[-1.29220697 -1.30163472 -0.08346051]\n",
            "16\n",
            "[-1.32202424 -1.3115738  -0.07352142]\n",
            "[-1.32202424 -1.31957188 -0.0815195 ]\n",
            "[-1.34201756 -1.35955852 -0.09151616]\n",
            "[-1.34388909 -1.35581546 -0.08964463]\n",
            "17\n",
            "[-1.37373976 -1.36576568 -0.07969441]\n",
            "[-1.37373976 -1.37385867 -0.08778739]\n",
            "[-1.39373494 -1.41384903 -0.09778498]\n",
            "[-1.39551232 -1.41029427 -0.0960076 ]\n",
            "18\n",
            "[-1.42539032 -1.4202536  -0.08604827]\n",
            "[-1.42539032 -1.42843873 -0.0942334 ]\n",
            "[-1.44538685 -1.46843179 -0.10423166]\n",
            "[-1.44707267 -1.46506014 -0.10254584]\n",
            "19\n",
            "[-1.476973   -1.47502692 -0.09257906]\n",
            "[-1.476973   -1.48330134 -0.10085348]\n",
            "[-1.4969705  -1.52329634 -0.11085223]\n",
            "[-1.49856748 -1.52010238 -0.10925525]\n",
            "[-1.52848606 -1.53007523 -0.09928239]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замечание:\n",
        "\n",
        "В случае, если у Вас возникли сложности с выполнением первого задания и, как следствие, у Вас не выходит сделать это, мы рекомендуем подробно ознакомиться с главой **Производные $\\frac{\\partial H}{\\partial \\omega_i}$** нашей [лекции](https://colab.research.google.com/drive/1xjX_YnXcRr8HSiYLByMHxEIAADqs7QES?usp=sharing)"
      ],
      "metadata": {
        "id": "zDcPxeLueFIk"
      }
    }
  ]
}